{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4320 Introduction to Machine Learning\n",
    "\n",
    "## A Template for the Course Project Submssion\n",
    "\n",
    "Note: This template is optional. You can design your Jupyter Notebook structure based on your competition and preference. However, we expect you practice as many machine learning skills you learned in this course as possible.\n",
    "\n",
    "**Please type your group name here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupName = \"OceanGate\"\n",
    "assert GroupName != \"\", 'Please enter your name in the above quotation marks, thanks!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. [Submission instructions](#si)\n",
    "1. [Understanding the problem](#1)\n",
    "2. [Data splitting](#2)\n",
    "3. [EDA](#3)\n",
    "4. [Feature engineering](#4)\n",
    "5. [Preprocessing and transformations](#5) \n",
    "6. [Baseline model](#6)\n",
    "8. [Different models](#8)\n",
    "9. [Feature selection](#9)\n",
    "10. [Hyperparameter optimization](#10)\n",
    "11. [Interpretation and feature importances](#11) \n",
    "12. [Results on the test set](#12)\n",
    "13. [Submit the predictions to Kaggle](#13)\n",
    "14. [Your takeaway from the course](#14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "\n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- Upload the .ipynb file to Canvas.\n",
    "- **Submit the screenshot of your Kaggle submission ranking and score** \n",
    "- Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n",
    "- Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "- Make sure that the plots and output are rendered properly in your submitted file. \n",
    "- Please keep your notebook clean and delete any throwaway code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "\n",
    "A few notes and tips when you work on this project: \n",
    "\n",
    "#### Tips\n",
    "1. The project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "\n",
    "#### Assessment\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn stuff\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import sklearn\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Other\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Pick your problem and explain the prediction problem <a name=\"1\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've opted for the [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic) competition, which aims to predict passenger survival based on 10 key features:\n",
    "- Pclass: Ticket class, represents socio-economic status\n",
    "    - 1 = Upper class\n",
    "    - 2 = Middle class\n",
    "    - 3 = Lower class\n",
    "- Name\n",
    "- Sex\n",
    "- Age\n",
    "- SibSp: Number of siblings and/or spouses aboard\n",
    "- Parch: Number of parents and/or children aboard\n",
    "- Ticket: Ticket number\n",
    "- Fare: Passenger fare\n",
    "- Cabin: Cabin number\n",
    "- Embarked: Port of embarkation\n",
    "    - (C)herbourg\n",
    "\t- (Q)ueenstown\n",
    "\t- (S)outhampton\n",
    "\n",
    "With 891 entries in the training set and 418 in the test set, the challenge is to leverage machine learning techniques to predict survival (boolean \"Survived\" column) for the test set, absent in the provided data. The \"Survived\" column serves as our target variable, with 0 indicating non-survival.\n",
    "\n",
    "One noteworthy observation is the potential utility of the \"Name\" feature for extracting titles, offering insights into social status. However, challenges arise, such as the significant number of missing values in the \"Cabin\" feature. Addressing these gaps will be crucial for robust model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Data splitting <a name=\"2\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "# train_df = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## EDA <a name=\"3\"></a>\n",
    "---\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 8\n",
    "bins = np.linspace(0, train_df['Age'].max(), num_bins+1)\n",
    "bins[-1] = np.inf\n",
    "age_group_labels = [\n",
    "    f\"{int(i)}-{int(j)}\"\n",
    "    if j != np.inf\n",
    "    else f\"{int(i)}+\"\n",
    "    for i, j in zip(bins[:-1], bins[1:])\n",
    "]\n",
    "age_groups = pd.cut(train_df[\"Age\"], bins=bins, labels=age_group_labels)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(\n",
    "    x=age_groups, data=train_df,\n",
    "    palette=\"Blues_d\", hue=\"Survived\",\n",
    ")\n",
    "plt.title('Survival Rate by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Number of Passengers')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(\n",
    "    x=age_groups, y=train_df['Survived'],\n",
    "    palette=\"Reds_d\", hue=age_groups,\n",
    "    estimator=lambda x: sum(x) / len(x) * 100 if len(x) > 0 else 0,\n",
    "    errorbar=None\n",
    ")\n",
    "plt.title('Survival Rate by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Survived (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different age groups are showing very different survival rates:\n",
    "- The age group 0-10 has the highest survival rate by far\n",
    "- The age groups from 10-60 show roughly the same survival rates\n",
    "- The age groups above 60 show very low survival rates.\n",
    "\n",
    "Let's see if these differences in survival rates are actually significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea from: https://medium.com/analytics-vidhya/constructing-heat-map-for-chi-square-test-of-independence-6d78aa2b140f\n",
    "\n",
    "p_values = np.zeros((num_bins, num_bins))\n",
    "for i, group1 in enumerate(age_group_labels):\n",
    "    for j, group2 in enumerate(age_group_labels):\n",
    "        contingency_table = pd.crosstab(\n",
    "            age_groups == group1,\n",
    "            age_groups == group2\n",
    "        )\n",
    "        _, p_values[i, j], _, _ = chi2_contingency(contingency_table)\n",
    "        \n",
    "mask = np.triu(np.ones_like(p_values, dtype=bool))\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(\n",
    "    p_values, annot=True, fmt='.4f', mask=mask,\n",
    "    xticklabels=age_group_labels, yticklabels=age_group_labels,\n",
    "    cmap='coolwarm',\n",
    ")\n",
    "\n",
    "plt.title('p-value for Age Groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test tells us that the difference we see in survival rate between 70+\n",
    "year olds and every other group is not significant.\n",
    "\n",
    "However, the difference in survival rates between most other groups seems\n",
    "significant, as many of them have p-values below 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decks = train_df[\"Cabin\"].str[0].fillna('Unknown')\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(\n",
    "    x=decks, data=train_df,\n",
    "    palette=\"Blues_d\", hue=\"Survived\",\n",
    ")\n",
    "plt.title('Survival Rate by Deck')\n",
    "plt.xlabel('Deck')\n",
    "plt.ylabel('Number of Passengers')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(\n",
    "    x=decks, y=train_df['Survived'],\n",
    "    palette=\"Reds_d\", hue=decks,\n",
    "    estimator=lambda x: sum(x) / len(x) * 100 if len(x) > 0 else 0,\n",
    "    errorbar=None\n",
    ")\n",
    "plt.title('Survival Rate by Deck')\n",
    "plt.xlabel('Deck')\n",
    "plt.ylabel('Survived (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea from: https://medium.com/analytics-vidhya/constructing-heat-map-for-chi-square-test-of-independence-6d78aa2b140f\n",
    "\n",
    "deck_names = decks.unique()\n",
    "p_values = np.zeros((len(deck_names), len(deck_names)))\n",
    "for i, deck1 in enumerate(deck_names):\n",
    "    for j, deck2 in enumerate(deck_names):\n",
    "        contingency_table = pd.crosstab(\n",
    "            decks == deck1,\n",
    "            decks == deck2,\n",
    "        )\n",
    "        _, p_values[i, j], _, _ = chi2_contingency(contingency_table)\n",
    "        \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    p_values, annot=True, fmt=\".4f\", cmap=\"coolwarm\", \n",
    "    xticklabels=deck_names, yticklabels=deck_names,\n",
    "    mask=np.triu(np.ones_like(p_values, dtype=bool)),\n",
    ")\n",
    "plt.title(\"p-values between different cabin decks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this heatmap that the differences in survival rate between the\n",
    "\"unknown\" cabin group and the other groups are very significant. This is important\n",
    "to note, as we otherwise may have just dropped the \"Cabin\" column due to the large\n",
    "number of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Feature engineering <a name=\"4\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out feature engineering. In other words, extract new features relevant for the problem and work with your new feature set. You may have to go back and forth between feature engineering and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having more family members on board might have made it harder to escape the sinking ship\n",
    "train_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\n",
    "test_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"] + 1\n",
    "\n",
    "# Being alone may have made it easier to escape the sinking ship\n",
    "train_df[\"IsAlone\"] = train_df[\"FamilySize\"] == 1\n",
    "test_df[\"IsAlone\"] = test_df[\"FamilySize\"] == 1\n",
    "\n",
    "# Title may signify social status, which may affect the survival rate.\n",
    "train_df[\"Title\"] = train_df[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\")\n",
    "test_df[\"Title\"] = test_df[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\")\n",
    "\n",
    "# As we saw earlier, age group is a good indicator of survival rate\n",
    "train_df[\"Age\"] = train_df[\"Age\"].fillna(train_df[\"Age\"].median())\n",
    "train_df[\"AgeGroup\"] = pd.cut(train_df[\"Age\"], bins=bins, labels=age_group_labels)\n",
    "test_df[\"Age\"] = test_df[\"Age\"].fillna(test_df[\"Age\"].median())\n",
    "test_df[\"AgeGroup\"] = pd.cut(test_df[\"Age\"], bins=bins, labels=age_group_labels)\n",
    "\n",
    "train_df[\"IsChild\"] = train_df[\"Age\"] < 15\n",
    "test_df[\"IsChild\"] = test_df[\"Age\"] < 15\n",
    "\n",
    "train_df[\"IsOld\"] = train_df[\"Age\"] > 70\n",
    "test_df[\"IsOld\"] = test_df[\"Age\"] > 70\n",
    "\n",
    "# We can also use the deck as an indicator of survival rate as we saw earlier\n",
    "train_df[\"IsUnknownDeck\"] = train_df[\"Cabin\"].str[0].isna()\n",
    "test_df[\"IsUnknownDeck\"] = test_df[\"Cabin\"].str[0].isna()\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Fare\", \"FamilySize\"]\n",
    "binary_features = [\"IsAlone\", \"Sex\", \"IsChild\", \"IsOld\", \"IsUnknownDeck\"]\n",
    "categorical_features = [\"Embarked\", \"Pclass\", \"Title\", \"AgeGroup\"]\n",
    "drop_features = [\"Age\", \"PassengerId\", \"Name\", \"Ticket\", \"Cabin\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "X = train_df.drop(columns=[\"Survived\"])\n",
    "y = train_df[\"Survived\"]\n",
    "\n",
    "numeric_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    StandardScaler(),\n",
    ")\n",
    "\n",
    "binary_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(drop=\"if_binary\"),\n",
    ")\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stolen from HW3\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Dummy model <a name=\"6\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.countplot(x='Survived', data=train_df, hue=\"Survived\", edgecolor='black')\n",
    "plt.title('Survival Count')\n",
    "plt.xlabel('Survival')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we know that the dummy will always predict 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "results_dict[\"dummy\"] = mean_std_cross_val_scores(\n",
    "    dummy, X, y, return_train_score=True\n",
    ")\n",
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X, y)\n",
    "predicted = dummy_clf.predict(test_df)\n",
    "\n",
    "dummy_submit_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': predicted})\n",
    "dummy_submit_df.to_csv('dummy_submission.csv', index=False)\n",
    "dummy_submit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## Models <a name=\"8\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try other models aside from a linear model. One of these models should be a tree-based ensemble model. \n",
    "2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn20 = KNeighborsClassifier(n_neighbors=20)\n",
    "rf = RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1)\n",
    "rfOptimized = RandomForestClassifier(max_depth=8, n_estimators=18)\n",
    "svm = SVC()\n",
    "vote = VotingClassifier(estimators=[('dt', dt), ('knn', knn), ('rf', rf), ('svm', svm)], voting='hard')\n",
    "lr = LinearRegression()\n",
    "models = { # Arbitrary hyperparameters, for now\n",
    "    \"decision_tree\": dt,\n",
    "    \"KNN\": knn,\n",
    "    \"KNN20\": knn20,\n",
    "    \"random_forest\": rf,\n",
    "    \"SVM\": svm,\n",
    "    \"voting\" : vote,\n",
    "    \"LinearRegression\": lr,\n",
    "    \"rfOptimized\": rfOptimized\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = make_pipeline(preprocessor, model)\n",
    "    results_dict[name] = mean_std_cross_val_scores(\n",
    "        pipe, X, y, return_train_score=True\n",
    "    )\n",
    "    pipe.fit(X, y)\n",
    "    predicted = pipe.predict(test_df)\n",
    "    submit_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': predicted})\n",
    "    submit_df.to_csv(f'{name}_submission.csv', index=False)\n",
    "\n",
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 9. Feature selection <a name=\"9\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to select relevant features. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have done feature selection when we did feature engineering and engineered the features that we wanted to drop into more relevant features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 10. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#This takes a while, so run it if needed but I got the best params for the random forest classifier in the optmized model\n",
    "# randomForestOpt = RandomForestClassifier()\n",
    "# pipeline = make_pipeline(preprocessor, randomForestOpt)\n",
    "# gs_rf = GridSearchCV(pipeline, param_grid={'randomforestclassifier__n_estimators': range(1, 50), 'randomforestclassifier__max_depth': range(1, 10)}, cv=5, scoring='accuracy')\n",
    "# gs_rf.fit(X, y)\n",
    "# gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that optimization helped a little but didn't make large imporvements in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 12. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our case the data was split for us, so we used all the training data then got our test data scores when submitting to kaggle. The best we got was from 0.77 percent. The best we got from cross validation testing was around 0.83 so its not that far off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 12. Kaggle results <a name=\"12\"></a>\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All our models are trained on the full test set, with the exemption of the cross validation testing we did. We got a score of 0.77 or 77%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 14. Your takeaway <a name=\"14\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "What is your biggest takeaway from the supervised machine learning material we have learned so far? Please write thoughtful answers.  Discuss other ideas that you did not try but could potentially improve the performance/interpretability . \n",
    "\n",
    "The biggest takeway I have learned from machine learning is varied it is. Models can be fairly simple to incredibly complex and hard to understand. It was also interesting to see the current research problems behind understanding why models make the decisions that they do. To improve our model we could get a better tuned voting ensemble. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
