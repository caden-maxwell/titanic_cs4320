{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4320 Introduction to Machine Learning\n",
    "\n",
    "## A Template for the Course Project Submssion\n",
    "\n",
    "Note: This template is optional. You can design your Jupyter Notebook structure based on your competition and preference. However, we expect you practice as many machine learning skills you learned in this course as possible.\n",
    "\n",
    "**Please type your group name here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GroupName = \"OceanGate\"\n",
    "assert GroupName != \"\", 'Please enter your name in the above quotation marks, thanks!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "0. [Submission instructions](#si)\n",
    "1. [Understanding the problem](#1)\n",
    "2. [Data splitting](#2)\n",
    "3. [EDA](#3)\n",
    "4. [Feature engineering](#4)\n",
    "5. [Preprocessing and transformations](#5) \n",
    "6. [Baseline model](#6)\n",
    "7. [Linear models](#7)\n",
    "8. [Different models](#8)\n",
    "9. [Feature selection](#9)\n",
    "10. [Hyperparameter optimization](#10)\n",
    "11. [Interpretation and feature importances](#11) \n",
    "12. [Results on the test set](#12)\n",
    "13. [Submit the predictions to Kaggle](#13)\n",
    "14. [Your takeaway from the course](#14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission instructions <a name=\"si\"></a>\n",
    "<hr>\n",
    "\n",
    "- It's your responsibility to make sure that the assignment is submitted by one of the group members before the deadline. \n",
    "- Upload the .ipynb file to Canvas.\n",
    "- **Submit the screenshot of your Kaggle submission ranking and score** \n",
    "- Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n",
    "- Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "- Make sure that the plots and output are rendered properly in your submitted file. \n",
    "- Please keep your notebook clean and delete any throwaway code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a name=\"in\"></a>\n",
    "\n",
    "A few notes and tips when you work on this project: \n",
    "\n",
    "#### Tips\n",
    "1. The project is open-ended, and while working on it, there might be some situations where you'll have to use your own judgment and make your own decisions (as you would be doing when you work as a data scientist). Make sure you explain your decisions whenever necessary. \n",
    "2. **Do not include everything you ever tried in your submission** -- it's fine just to have your final code. That said, your code should be reproducible and well-documented. For example, if you chose your hyperparameters based on some hyperparameter optimization experiment, you should leave in the code for that experiment so that someone else could re-run it and obtain the same hyperparameters, rather than mysteriously just setting the hyperparameters to some (carefully chosen) values in your code. \n",
    "3. If you realize that you are repeating a lot of code try to organize it in functions. Clear presentation of your code, experiments, and results is the key to be successful in this lab. You may use code from lecture notes or previous lab solutions with appropriate attributions. \n",
    "\n",
    "#### Assessment\n",
    "We plan to grade fairly and leniently. We don't have some secret target score that you need to achieve to get a good grade. **You'll be assessed on demonstration of mastery of course topics, clear presentation, and the quality of your analysis and results.** For example, if you just have a bunch of code and no text or figures, that's not good. If you do a bunch of sane things and get a lower accuracy than your friend, don't sweat it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "# Other\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1. Pick your problem and explain the prediction problem <a name=\"1\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've opted for the [Titanic - Machine Learning from Disaster](https://www.kaggle.com/competitions/titanic) competition, which aims to predict passenger survival based on 10 key features:\n",
    "- Pclass: Ticket class, represents socio-economic status\n",
    "    - 1 = Upper class\n",
    "    - 2 = Middle class\n",
    "    - 3 = Lower class\n",
    "- Name\n",
    "- Sex\n",
    "- Age\n",
    "- SibSp: Number of siblings and/or spouses aboard\n",
    "- Parch: Number of parents and/or children aboard\n",
    "- Ticket: Ticket number\n",
    "- Fare: Passenger fare\n",
    "- Cabin: Cabin number\n",
    "- Embarked: Port of embarkation\n",
    "    - (C)herbourg\n",
    "\t- (Q)ueenstown\n",
    "\t- (S)outhampton\n",
    "\n",
    "With 891 entries in the training set and 418 in the test set, the challenge is to leverage machine learning techniques to predict survival (boolean \"Survived\" column) for the test set, absent in the provided data. The \"Survived\" column serves as our target variable, with 0 indicating non-survival.\n",
    "\n",
    "One noteworthy observation is the potential utility of the \"Name\" feature for extracting titles, offering insights into social status. However, challenges arise, such as the significant number of missing values in the \"Cabin\" feature. Addressing these gaps will be crucial for robust model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 2. Data splitting <a name=\"2\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.read_csv('/kaggle/input/titanic/test.csv')\n",
    "# train_df = pd.read_csv('/kaggle/input/titanic/train.csv')\n",
    "\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 3. EDA <a name=\"3\"></a>\n",
    "---\n",
    "\n",
    "1. Perform exploratory data analysis on the train set.\n",
    "2. Include at least two summary statistics and two visualizations that you find useful, and accompany each one with a sentence explaining it.\n",
    "3. Summarize your initial observations about the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m sns\u001b[38;5;241m.\u001b[39mcountplot(\n\u001b[0;32m     16\u001b[0m     x\u001b[38;5;241m=\u001b[39mage_groups, data\u001b[38;5;241m=\u001b[39mtrain_df,\n\u001b[0;32m     17\u001b[0m     palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBlues_d\u001b[39m\u001b[38;5;124m\"\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurvived\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m )\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurvival Rate by Age Group\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge Group\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_bins = 8\n",
    "bins = np.linspace(0, train_df['Age'].max(), num_bins+1)\n",
    "bins[-1] = np.inf\n",
    "age_group_labels = [\n",
    "    f\"{int(i)}-{int(j)}\"\n",
    "    if j != np.inf\n",
    "    else f\"{int(i)}+\"\n",
    "    for i, j in zip(bins[:-1], bins[1:])\n",
    "]\n",
    "age_groups = pd.cut(train_df[\"Age\"], bins=bins, labels=age_group_labels)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(\n",
    "    x=age_groups, data=train_df,\n",
    "    palette=\"Blues_d\", hue=\"Survived\",\n",
    ")\n",
    "plt.title('Survival Rate by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Number of Passengers')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(\n",
    "    x=age_groups, y=train_df['Survived'],\n",
    "    palette=\"Reds_d\", hue=age_groups,\n",
    "    legend=False,\n",
    "    estimator=lambda x: sum(x) / len(x) * 100 if len(x) > 0 else 0,\n",
    "    errorbar=None\n",
    ")\n",
    "plt.title('Survival Rate by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Survived (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different age groups are showing very different survival rates:\n",
    "- The age group 0-10 has the highest survival rate by far\n",
    "- The age groups from 10-60 show roughly the same survival rates\n",
    "- The age groups above 60 show very low survival rates.\n",
    "\n",
    "Let's see if these differences in survival rates are actually significant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea from: https://medium.com/analytics-vidhya/constructing-heat-map-for-chi-square-test-of-independence-6d78aa2b140f\n",
    "\n",
    "p_values = np.zeros((num_bins, num_bins))\n",
    "for i, group1 in enumerate(age_group_labels):\n",
    "    for j, group2 in enumerate(age_group_labels):\n",
    "        contingency_table = pd.crosstab(\n",
    "            age_groups == group1,\n",
    "            age_groups == group2\n",
    "        )\n",
    "        _, p_values[i, j], _, _ = chi2_contingency(contingency_table)\n",
    "        \n",
    "mask = np.triu(np.ones_like(p_values, dtype=bool))\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "sns.heatmap(\n",
    "    p_values, annot=True, fmt='.4f', mask=mask,\n",
    "    xticklabels=age_group_labels, yticklabels=age_group_labels,\n",
    "    cmap='coolwarm',\n",
    ")\n",
    "\n",
    "plt.title('p-value for Age Groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test tells us that the difference we see in survival rate between 70+\n",
    "year olds and every other group is not significant.\n",
    "\n",
    "However, the difference in survival rates between most other groups seems\n",
    "significant, as many of them have p-values below 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decks = train_df[\"Cabin\"].str[0].fillna('Unknown')\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.countplot(\n",
    "    x=decks, data=train_df,\n",
    "    palette=\"Blues_d\", hue=\"Survived\",\n",
    ")\n",
    "plt.title('Survival Rate by Deck')\n",
    "plt.xlabel('Deck')\n",
    "plt.ylabel('Number of Passengers')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(\n",
    "    x=decks, y=train_df['Survived'],\n",
    "    palette=\"Reds_d\", hue=decks,\n",
    "    legend=False,\n",
    "    estimator=lambda x: sum(x) / len(x) * 100 if len(x) > 0 else 0,\n",
    "    errorbar=None\n",
    ")\n",
    "plt.title('Survival Rate by Deck')\n",
    "plt.xlabel('Deck')\n",
    "plt.ylabel('Survived (%)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea from: https://medium.com/analytics-vidhya/constructing-heat-map-for-chi-square-test-of-independence-6d78aa2b140f\n",
    "\n",
    "deck_names = decks.unique()\n",
    "p_values = np.zeros((len(deck_names), len(deck_names)))\n",
    "for i, deck1 in enumerate(deck_names):\n",
    "    for j, deck2 in enumerate(deck_names):\n",
    "        contingency_table = pd.crosstab(\n",
    "            decks == deck1,\n",
    "            decks == deck2,\n",
    "        )\n",
    "        _, p_values[i, j], _, _ = chi2_contingency(contingency_table)\n",
    "        \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    p_values, annot=True, fmt=\".4f\", cmap=\"coolwarm\", \n",
    "    xticklabels=deck_names, yticklabels=deck_names,\n",
    "    mask=np.triu(np.ones_like(p_values, dtype=bool)),\n",
    ")\n",
    "plt.title(\"p-values between different cabin decks\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this heatmap that the differences in survival rate between the\n",
    "\"unknown\" cabin group and the other groups are very significant. This is important\n",
    "to note, as we otherwise may have just dropped the \"Cabin\" column due to the large\n",
    "number of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 4. Feature engineering <a name=\"4\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Carry out feature engineering. In other words, extract new features relevant for the problem and work with your new feature set. You may have to go back and forth between feature engineering and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having more family members on board might have made it harder to escape the sinking ship\n",
    "train_df[\"FamilySize\"] = train_df[\"SibSp\"] + train_df[\"Parch\"] + 1\n",
    "test_df[\"FamilySize\"] = test_df[\"SibSp\"] + test_df[\"Parch\"] + 1\n",
    "\n",
    "# Being alone may have made it easier to escape the sinking ship\n",
    "train_df[\"IsAlone\"] = train_df[\"FamilySize\"] == 1\n",
    "test_df[\"IsAlone\"] = test_df[\"FamilySize\"] == 1\n",
    "\n",
    "# Title may signify social status, which may affect the survival rate.\n",
    "train_df[\"Title\"] = train_df[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\")\n",
    "test_df[\"Title\"] = test_df[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\")\n",
    "\n",
    "# As we saw earlier, age group is a good indicator of survival rate\n",
    "train_df[\"Age\"] = train_df[\"Age\"].fillna(train_df[\"Age\"].median())\n",
    "train_df[\"AgeGroup\"] = pd.cut(train_df[\"Age\"], bins=bins, labels=age_group_labels)\n",
    "test_df[\"Age\"] = test_df[\"Age\"].fillna(test_df[\"Age\"].median())\n",
    "test_df[\"AgeGroup\"] = pd.cut(test_df[\"Age\"], bins=bins, labels=age_group_labels)\n",
    "\n",
    "train_df[\"IsChild\"] = train_df[\"Age\"] < 15\n",
    "test_df[\"IsChild\"] = test_df[\"Age\"] < 15\n",
    "\n",
    "train_df[\"IsOld\"] = train_df[\"Age\"] > 70\n",
    "test_df[\"IsOld\"] = test_df[\"Age\"] > 70\n",
    "\n",
    "# We can also use the deck as an indicator of survival rate as we saw earlier\n",
    "train_df[\"IsUnknownDeck\"] = train_df[\"Cabin\"].str[0].isna()\n",
    "test_df[\"IsUnknownDeck\"] = test_df[\"Cabin\"].str[0].isna()\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 5. Preprocessing and transformations <a name=\"5\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Identify different feature types and the transformations you would apply on each feature type. \n",
    "2. Define a column transformer, if necessary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Fare\", \"FamilySize\"]\n",
    "binary_features = [\"IsAlone\", \"Sex\", \"IsChild\", \"IsOld\", \"IsUnknownDeck\"]\n",
    "categorical_features = [\"Embarked\", \"Pclass\", \"Title\", \"AgeGroup\"]\n",
    "drop_features = [\"Age\", \"PassengerId\", \"Name\", \"Ticket\", \"Cabin\", \"SibSp\", \"Parch\"]\n",
    "\n",
    "X = train_df.drop(columns=[\"Survived\"])\n",
    "y = train_df[\"Survived\"]\n",
    "\n",
    "numeric_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    StandardScaler(),\n",
    ")\n",
    "\n",
    "binary_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(drop=\"if_binary\"),\n",
    ")\n",
    "\n",
    "categorical_transformer = make_pipeline(\n",
    "    SimpleImputer(strategy=\"most_frequent\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (numeric_transformer, numeric_features),\n",
    "    (binary_transformer, binary_features),\n",
    "    (categorical_transformer, categorical_features),\n",
    "    (\"drop\", drop_features),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stolen from HW3\n",
    "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
    "    \"\"\"\n",
    "    Returns mean and std of cross validation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :\n",
    "        scikit-learn model\n",
    "    X_train : numpy array or pandas DataFrame\n",
    "        X in the training data\n",
    "    y_train :\n",
    "        y in the training data\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        pandas Series with mean scores from cross_validation\n",
    "    \"\"\"\n",
    "\n",
    "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
    "\n",
    "    mean_scores = pd.DataFrame(scores).mean()\n",
    "    std_scores = pd.DataFrame(scores).std()\n",
    "    out_col = []\n",
    "\n",
    "    for i in range(len(mean_scores)):\n",
    "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
    "\n",
    "    return pd.Series(data=out_col, index=mean_scores.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 6. Baseline model <a name=\"6\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try `scikit-learn`'s baseline model and report results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.countplot(x='Survived', data=train_df, hue=\"Survived\", edgecolor='black', legend=False)\n",
    "plt.title('Survival Count')\n",
    "plt.xlabel('Survival')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we know that the dummy will always predict 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "results_dict[\"dummy\"] = mean_std_cross_val_scores(\n",
    "    dummy, X, y, return_train_score=True\n",
    ")\n",
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X, y)\n",
    "predicted = dummy_clf.predict(test_df)\n",
    "\n",
    "dummy_submit_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': predicted})\n",
    "dummy_submit_df.to_csv('dummy_submission.csv', index=False)\n",
    "dummy_submit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 7. Linear models <a name=\"7\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try a linear model as a first real attempt. \n",
    "2. Carry out hyperparameter tuning to explore different values for the complexity hyperparameter. \n",
    "3. Report cross-validation scores along with standard deviation. \n",
    "4. Summarize your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLinear = LinearRegression()\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "average_age = df['Age'].mean()\n",
    "df['Age'].fillna(average_age, inplace=True)\n",
    "\n",
    "average_fare = df['Fare'].mean()\n",
    "df['Fare'].fillna(average_fare, inplace=True)\n",
    "\n",
    "\n",
    "df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "\n",
    "XL = df[[\"Fare\"]]\n",
    "yL = train_df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(XL, yL, test_size=0.2, random_state=42)\n",
    "\n",
    "modelLinear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelLinear.predict(X_test)\n",
    "\n",
    "plt.scatter(X_test, y_test, color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "plt.xlabel('Fare')\n",
    "plt.ylabel(target)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "XL = df[[\"Age\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XL, yL, test_size=0.2, random_state=42)\n",
    "\n",
    "modelLinear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelLinear.predict(X_test)\n",
    "\n",
    "plt.scatter(X_test, y_test, color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel(target)\n",
    "plt.show()\n",
    "\n",
    "XL = df[[\"Sex\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XL, yL, test_size=0.2, random_state=42)\n",
    "\n",
    "modelLinear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelLinear.predict(X_test)\n",
    "\n",
    "plt.scatter(X_test, y_test, color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel(target)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "XL = df[[\"Pclass\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XL, yL, test_size=0.2, random_state=42)\n",
    "\n",
    "modelLinear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelLinear.predict(X_test)\n",
    "\n",
    "plt.scatter(X_test, y_test, color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "plt.xlabel('Pclass')\n",
    "plt.ylabel(target)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "XL = df[[\"SibSp\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XL, yL, test_size=0.2, random_state=42)\n",
    "\n",
    "modelLinear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelLinear.predict(X_test)\n",
    "\n",
    "plt.scatter(X_test, y_test, color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "plt.xlabel('SibSp')\n",
    "plt.ylabel(target)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "XL = df[[\"Parch\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(XL, yL, test_size=0.2, random_state=42)\n",
    "\n",
    "modelLinear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelLinear.predict(X_test)\n",
    "\n",
    "plt.scatter(X_test, y_test, color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "plt.xlabel('Parch')\n",
    "plt.ylabel(target)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "XL = df[['Parch', 'SibSp', 'Pclass', 'Sex', 'Age', 'Fare']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(XL, yL, test_size=0.2, random_state=42)\n",
    "\n",
    "modelLinear.fit(X_train, y_train)\n",
    "\n",
    "y_pred = modelLinear.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# Coefficients and intercept\n",
    "print('Coefficients:', modelLinear.coef_)\n",
    "print('Intercept:', modelLinear.intercept_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 8. Different models <a name=\"8\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "1. Try other models aside from a linear model. One of these models should be a tree-based ensemble model. \n",
    "2. Summarize your results in terms of overfitting/underfitting and fit and score times. Can you beat a linear model? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "models = { # Arbitrary hyperparameters, for now\n",
    "    \"decision_tree\": DecisionTreeClassifier(max_depth=5), \n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=10),\n",
    "    \"random_forest\": RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    \"SVM\": SVC()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    pipe = make_pipeline(preprocessor, model)\n",
    "    results_dict[name] = mean_std_cross_val_scores(\n",
    "        pipe, X, y, return_train_score=True\n",
    "    )\n",
    "    pipe.fit(X, y)\n",
    "    predicted = pipe.predict(test_df)\n",
    "    submit_df = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': predicted})\n",
    "    submit_df.to_csv(f'{name}_submission.csv', index=False)\n",
    "\n",
    "pd.DataFrame(results_dict).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 9. Feature selection <a name=\"9\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to select relevant features. Do the results improve with feature selection? Summarize your results. If you see improvements in the results, keep feature selection in your pipeline. If not, you may abandon it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 10. Hyperparameter optimization <a name=\"10\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Make some attempts to optimize hyperparameters for the models you've tried and summarize your results. In at least one case you should be optimizing multiple hyperparameters for a single model. You may use `sklearn`'s methods for hyperparameter optimization or fancier Bayesian optimization methods. \n",
    "  - [GridSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)   \n",
    "  - [RandomizedSearchCV](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
    "  - [scikit-optimize](https://github.com/scikit-optimize/scikit-optimize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 11. Interpretation and feature importances <a name=\"11\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Use the methods we saw in class (e.g., `eli5`, `shap`) (or any other methods of your choice) to examine the most important features of one of the non-linear models. \n",
    "2. Summarize your observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 12. Results on the test set <a name=\"12\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "1. Try your best performing model on the test data (from train test split) and report test scores. \n",
    "2. Do the test scores agree with the validation scores from before? To what extent do you trust your results? Do you think you've had issues with optimization bias? \n",
    "3. Take one or two test predictions and explain these individual predictions (e.g., with SHAP force plots).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 13. Submit the predictions to Kaggle <a name=\"13\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "Retrain the best model on the whole training dataset and upload the predicted output on the test set to Kaggle. Report your final test score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 14. Your takeaway <a name=\"14\"></a>\n",
    "<hr>\n",
    "\n",
    "**Your tasks:**\n",
    "\n",
    "What is your biggest takeaway from the supervised machine learning material we have learned so far? Please write thoughtful answers.  Discuss other ideas that you did not try but could potentially improve the performance/interpretability . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<br><br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
